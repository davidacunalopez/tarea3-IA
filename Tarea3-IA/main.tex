% !TeX program = pdflatex
\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

% ---- Paquetes ----
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amssymb}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{array}
\usepackage{hyperref}
\usepackage{multirow}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\sisetup{detect-weight=true,detect-family=true}

% Rutas comunes para figuras
\graphicspath{{figs/}{figures/}{images/}{img/}{./}}

% --- Compactación de floats/captions ---
\captionsetup{font=footnotesize}
\setlength{\textfloatsep}{6pt plus 1pt minus 2pt}
\setlength{\floatsep}{6pt plus 1pt minus 2pt}
\setlength{\intextsep}{6pt plus 1pt minus 2pt}
\setlength{\abovecaptionskip}{4pt}
\setlength{\belowcaptionskip}{0pt}

% --- Política de colocación de floats ---
\renewcommand{\topfraction}{0.9}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\textfraction}{0.07}
\renewcommand{\floatpagefraction}{0.8}
\renewcommand{\dbltopfraction}{0.9}
\renewcommand{\dblfloatpagefraction}{0.8}
\setcounter{topnumber}{5}
\setcounter{bottomnumber}{5}
\setcounter{totalnumber}{10}

% --- Utilidades de placeholders de figuras ---
\newcommand{\placeholderbox}[2][5cm]{%
  \fbox{\begin{minipage}[c][#1][c]{0.9\linewidth}\centering \textbf{Placeholder:} #2\end{minipage}}}

% label, caption, filename
\newcommand{\placefigure}[3]{%
\begin{figure}[!t]\centering
\IfFileExists{#3}{\includegraphics[width=\linewidth]{#3}}{\placeholderbox{#3}}
\caption{#2}\label{#1}\end{figure}}

% width, filename, subcaption, label
\newcommand{\placesubfig}[4]{%
\begin{subfigure}{#1}
\centering
\IfFileExists{#2}{\includegraphics[width=\linewidth]{#2}}{\placeholderbox{#2}}
\caption{#3}\label{#4}
\end{subfigure}}

% ---- Título y autores ----
\title{Implementación de Sistema RAG con Agentes para Consulta de Apuntes de Inteligencia Artificial\vspace{-0.35em}}

\author{\IEEEauthorblockN{1\textsuperscript{st} Priscilla Jim\'enez Salgado}
\IEEEauthorblockA{Estudiante, Escuela de Ingenier\'ia en Computaci\'on\\
Tecnol\'ogico de Costa Rica (TEC)\\
Email: 2021022576@estudiantec.cr}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Fabi\'an Araya Ortega}
\IEEEauthorblockA{Estudiante, Escuela de Ingenier\'ia en Computaci\'on\\
Tecnol\'ogico de Costa Rica (TEC)\\
Email: fabian.araya@estudiantec.cr}
\and
\IEEEauthorblockN{3\textsuperscript{rd} David Acu\~na L\'opez}
\IEEEauthorblockA{Estudiante, Escuela de Ingenier\'ia en Computaci\'on\\
Tecnol\'ogico de Costa Rica (TEC)\\
Email: rodolfoide69@estudiantec.cr}
\IEEEauthorrefmark{1}}

\begin{document}
\raggedbottom
\maketitle

\begin{abstract}
Este trabajo presenta la implementación de un sistema de Recuperación Aumentada por Generación (RAG) para consulta de apuntes del curso de Inteligencia Artificial. El sistema procesa \num{46} documentos PDF, aplica técnicas de normalización y segmentación de texto, genera embeddings semánticos y construye bases vectoriales para búsqueda semántica. Se implementan dos estrategias de segmentación: chunks fijos con solapamiento y segmentación por encabezados, generando \num{227} y \num{349} fragmentos respectivamente. Se utilizan embeddings del modelo \texttt{sentence-transformers/all-MiniLM-L6-v2} (dimensión 384) y se almacenan en bases FAISS. Los resultados muestran que la segmentación por encabezados produce fragmentos más coherentes semánticamente, mientras que los chunks fijos ofrecen mayor control sobre la longitud. El sistema permite búsqueda semántica eficiente con herramientas RAG que retornan fragmentos relevantes, documentos de origen y autores, estableciendo una base sólida para un agente conversacional.
\end{abstract}

\begin{IEEEkeywords}
RAG, Retrieval Augmented Generation, Embeddings, Búsqueda semántica, FAISS, Segmentación de texto, Procesamiento de lenguaje natural, Agentes conversacionales
\end{IEEEkeywords}

\section{Introducci\'on}
Se desarrolló un sistema completo de Recuperación Aumentada por Generación (RAG) para consulta de apuntes del curso de Inteligencia Artificial. El sistema consta de tres componentes principales: (1) preprocesamiento y segmentación de documentos PDF, (2) generación de embeddings y construcción de bases vectoriales, y (3) herramientas de búsqueda semántica. El objetivo es crear una base de conocimiento estructurada que permita a un agente conversacional responder preguntas sobre el contenido del curso, consultando primero los apuntes y citando las fuentes apropiadas.

\section{Conjunto de Datos y Preprocesamiento}
\subsection{Descripción del Conjunto de Datos}
El conjunto de datos contiene \num{46} documentos PDF correspondientes a apuntes del curso de Inteligencia Artificial. Cada documento incluye metadata con las siguientes columnas: \texttt{id\_doc}, \texttt{nombre\_archivo}, \texttt{autor}, \texttt{fecha} y \texttt{tema}. Todos los documentos fueron procesados exitosamente, generando textos normalizados y dos tipos de segmentación.

\begin{table}[H]\centering\caption{Características del conjunto de datos}
\label{tab:estructura}
\begin{tabular}{lS}
\toprule
\textbf{Caracter\'istica} & {\textbf{Valor}}\\
\midrule
Documentos PDF & 46\\
Columnas de metadata & 5 (\texttt{id\_doc}, \texttt{nombre\_archivo}, \texttt{autor}, \texttt{fecha}, \texttt{tema}) \\
Fragmentos Segmentación A & 227\\
Fragmentos Segmentación B & 349\\
Faltantes & 0 \\
Errores de procesamiento & 0\\
\bottomrule
\end{tabular}
\end{table}

\subsection{Normalización de Texto}
Se aplicó un pipeline de normalización consistente en seis etapas para garantizar consistencia y calidad del texto extraído:

\begin{enumerate}
\item \textbf{Unicode NFC}: Normalización de caracteres Unicode para mantener tildes y caracteres especiales correctos.
\item \textbf{Limpieza de caracteres de control}: Eliminación de caracteres de control, excepto saltos de línea (\texttt{\textbackslash n}) y tabulaciones (\texttt{\textbackslash t}).
\item \textbf{Estandarización de comillas y guiones}: Conversión de comillas tipográficas (`` '' `` '') y guiones (—, –, −) a caracteres ASCII estándar (", ', -).
\item \textbf{Unión de palabras cortadas}: Detección y unión de palabras cortadas por guion al final de línea (e.g., ``infor-\textbackslash nmación'' → ``información'').
\item \textbf{Colapso de espacios}: Reducción de espacios múltiples y saltos de línea excesivos a formatos estándar.
\item \textbf{Conversión a minúsculas}: Normalización a minúsculas para permitir comparación consistente entre segmentaciones.
\end{enumerate}

Esta normalización asegura que el texto esté en un formato limpio y consistente, facilitando la segmentación y la generación de embeddings.

\subsection{Segmentación de Texto}
Se implementaron dos estrategias de segmentación para comparar su efectividad en la recuperación de información:

\subsubsection{Segmentación A: Chunks Fijos con Solapamiento}
Esta estrategia divide el texto en fragmentos de tamaño fijo de aproximadamente \num{400} palabras con un solapamiento de \num{80} palabras entre fragmentos consecutivos.

\textbf{Ventajas:}
\begin{itemize}
\item Control preciso sobre la longitud de los fragmentos
\item Útil para evaluación reproducible y comparación de métricas
\item Distribución uniforme de contenido
\end{itemize}

\textbf{Desventajas:}
\begin{itemize}
\item Puede cortar ideas o conceptos a la mitad
\item No respeta la estructura semántica del documento
\end{itemize}

Esta segmentación generó \num{227} fragmentos en total.

\subsubsection{Segmentación B: Por Encabezados y Secciones}
Esta estrategia identifica encabezados y secciones del documento usando patrones como:
\begin{itemize}
\item Palabras clave: Abstract, Resumen, Introducción, Conclusión, Referencias, Agradecimientos
\item Numeración: numerales (1., 2., 3., ...), romanos (I., II., III., ...)
\item Títulos en MAYÚSCULAS
\end{itemize}

Las secciones se fusionan si son menores a \num{120} palabras para asegurar contexto mínimo.

\textbf{Ventajas:}
\begin{itemize}
\item Mantiene unidades semánticas coherentes
\item Respeta la estructura del documento
\item Potencialmente mejor para grounding en respuestas
\end{itemize}

\textbf{Desventajas:}
\begin{itemize}
\item Depende de patrones editoriales consistentes
\item Tamaño de fragmentos variable
\end{itemize}

Esta segmentación generó \num{349} fragmentos en total, un 54\% más que la segmentación A, lo que sugiere que los documentos tienen una estructura bien definida con múltiples secciones.

\subsection{Salidas del Preprocesamiento}
El proceso de preprocesamiento genera los siguientes archivos:

\begin{itemize}
\item \texttt{base\_documentos.jsonl} y \texttt{base\_documentos.parquet}: Textos completos normalizados por documento con metadata completa.
\item \texttt{seg\_a.jsonl}: Fragmentos de la segmentación A con campos \texttt{id\_doc}, \texttt{chunk\_id}, \texttt{segmentacion}, \texttt{idx}, \texttt{texto}, \texttt{autor}, \texttt{fecha}, \texttt{tema}.
\item \texttt{seg\_b.jsonl}: Fragmentos de la segmentación B con la misma estructura.
\item \texttt{txt\_por\_doc/}: Archivos de texto individuales por documento para inspección rápida.
\end{itemize}

\section{Generación de Embeddings y Base Vectorial}
\subsection{Modelo de Embeddings}
Se utilizó el modelo \texttt{sentence-transformers/all-MiniLM-L6-v2} para generar embeddings semánticos. Este modelo fue seleccionado por las siguientes razones:

\begin{itemize}
\item \textbf{Gratuito y local}: No requiere API keys ni conexión a servicios externos
\item \textbf{Optimizado para búsqueda}: Diseñado específicamente para tareas de recuperación de información
\item \textbf{Dimensión eficiente}: 384 dimensiones, balanceando calidad y eficiencia computacional
\item \textbf{Rendimiento}: Buen desempeño en tareas de similitud semántica
\end{itemize}

El modelo se configuró con normalización de embeddings activada (\texttt{normalize\_embeddings=True}) para mejorar la calidad de la búsqueda mediante similitud de coseno.

\subsection{Tokenización y Verificación}
Se implementó verificación de tokens usando \texttt{tiktoken} para asegurar que los fragmentos no excedan los límites recomendados. Un fragmento de ejemplo con \num{3170} caracteres corresponde a aproximadamente \num{822} tokens, muy por debajo del límite recomendado de \num{8000} tokens para embeddings.

\subsection{Almacenamiento en Base Vectorial}
Se utilizó FAISS (Facebook AI Similarity Search) para almacenar y buscar eficientemente en los embeddings. Se crearon dos bases vectoriales independientes:

\begin{itemize}
\item \texttt{vectorstore\_a}: Almacena embeddings de la segmentación A (\num{227} documentos)
\item \texttt{vectorstore\_b}: Almacena embeddings de la segmentación B (\num{349} documentos)
\end{itemize}

FAISS utiliza índices optimizados para búsqueda por similitud de coseno, permitiendo búsquedas rápidas incluso con grandes volúmenes de datos. Los índices se guardan en disco para evitar regenerarlos en cada ejecución.

\subsection{Herramientas RAG}
Se implementaron herramientas RAG usando LangChain que permiten:
\begin{enumerate}
\item Búsqueda semántica en la base vectorial
\item Retorno de fragmentos relevantes con scores de similitud
\item Información de metadatos: documento de origen, chunk ID, autor
\end{enumerate}

Cada herramienta RAG (\texttt{rag\_search\_A} y \texttt{rag\_search\_B}) consulta su respectiva base vectorial y retorna los top-k resultados (por defecto k=5) formateados con:
\begin{itemize}
\item Score de similitud (distancia coseno)
\item Fragmento de texto (primeros 500 caracteres)
\item ID del documento y chunk
\item Autor del documento
\end{itemize}

\section{An\'alisis de Resultados}
\subsection{Comparación de Segmentaciones}
La comparación entre ambas segmentaciones revela diferencias significativas:

\begin{table}[H]\centering\caption{Comparación de segmentaciones}
\label{tab:segmentaciones}
\begin{tabular}{lS[table-format=3.0]S[table-format=3.0]}
\toprule
\textbf{Métrica} & {\textbf{Segmentación A}} & {\textbf{Segmentación B}}\\
\midrule
Número de fragmentos & 227 & 349 \\
Tamaño promedio (palabras) & $\approx$ 400 & Variable \\
Coherencia semántica & Media & Alta \\
Uniformidad de tamaño & Alta & Media \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Resultados de Búsqueda Semántica}
Se realizaron pruebas de búsqueda semántica con la consulta: ``inteligencia artificial y aprendizaje automático''. Los resultados muestran:

\subsubsection{Segmentación A (Top 3)}
\begin{enumerate}
\item Score: 0.7227 | Autor: Andrey Ureña Bermúdez
\item Score: 0.7863 | Autor: Luis Alfredo González Sánchez
\item Score: 0.8033 | Autor: Rodolfo David Acuña López
\end{enumerate}

\subsubsection{Segmentación B (Top 3)}
\begin{enumerate}
\item Score: 0.6992 | Autor: Andrey Ureña Bermúdez
\item Score: 0.7228 | Autor: Rodolfo David Acuña López
\item Score: 0.7557 | Autor: Priscilla Jiménez Salgado
\end{enumerate}

Los scores de similitud oscilan entre 0.69 y 0.80, indicando que ambas segmentaciones encuentran contenido relevante. La segmentación A muestra scores ligeramente más altos (promedio 0.77) que la B (promedio 0.73), lo que podría deberse a que los fragmentos de tamaño fijo capturan mejor términos específicos de la consulta.

\subsection{Análisis de Calidad de Embeddings}
La generación de embeddings se verificó exitosamente:
\begin{itemize}
\item Dimensión: 384 valores por embedding
\item Normalización: Embeddings normalizados (norma L2 = 1)
\item Rango de valores: Distribución típica de embeddings normalizados (-1 a 1)
\end{itemize}

Un ejemplo de embedding generado muestra valores típicos: [-0.020, 0.109, -0.009, -0.027, -0.064, ...], confirmando que la normalización funciona correctamente.

\subsection{Herramientas Implementadas}
Se implementaron tres herramientas principales:

\begin{enumerate}
\item \texttt{rag\_search\_A}: Búsqueda en apuntes usando segmentación A (chunks fijos). Útil para búsquedas de fragmentos específicos.
\item \texttt{rag\_search\_B}: Búsqueda en apuntes usando segmentación B (encabezados). Mejor para temas completos y contextos amplios.
\item \texttt{web\_search}: Búsqueda web (solo cuando se solicite explícitamente, según las restricciones del sistema).
\end{enumerate}

Las herramientas RAG retornan información estructurada que incluye:
\begin{itemize}
\item Fragmentos de texto relevantes
\item Documentos de origen (ID del documento)
\item Chunk IDs para trazabilidad
\item Autores para citación apropiada
\end{itemize}

\section{Discusi\'on}
\subsection{Ventajas del Sistema Implementado}
El sistema presenta varias ventajas:
\begin{itemize}
\item \textbf{Procesamiento completo}: Todos los documentos PDF fueron procesados exitosamente sin errores
\item \textbf{Dualidad de segmentaciones}: Permite comparar estrategias y elegir la más adecuada según el caso de uso
\item \textbf{Embeddings eficientes}: Modelo local y gratuito con buen rendimiento
\item \textbf{Búsqueda rápida}: FAISS permite búsquedas semánticas en tiempo real
\item \textbf{Trazabilidad}: Cada fragmento mantiene metadata completa para citación
\end{itemize}

\subsection{Limitaciones y Trabajo Futuro}
Las principales limitaciones identificadas son:
\begin{itemize}
\item \textbf{Segmentación A}: Puede cortar conceptos a la mitad debido al tamaño fijo
\item \textbf{Segmentación B}: Depende de patrones editoriales consistentes en los PDFs
\item \textbf{Embeddings}: Modelo con 384 dimensiones puede ser limitado para tareas muy complejas
\item \textbf{Idioma}: El modelo está optimizado principalmente para inglés, aunque funciona bien con español
\end{itemize}

Como trabajo futuro se sugiere:
\begin{itemize}
\item Evaluación cuantitativa con métricas como Recall@k y Precision@k
\item Comparación con modelos de embeddings más grandes (e.g., \texttt{text-embedding-3-small} de OpenAI)
\item Implementación de re-ranking para mejorar la precisión
\item Análisis de tiempo de respuesta para optimización
\item Evaluación manual de la calidad de las respuestas generadas
\end{itemize}

\section{Conclusiones}
Se implementó exitosamente un sistema RAG completo para consulta de apuntes del curso de Inteligencia Artificial. El sistema procesa \num{46} documentos PDF, aplica normalización exhaustiva y genera dos tipos de segmentación, produciendo \num{227} y \num{349} fragmentos respectivamente. Se utilizan embeddings del modelo \texttt{sentence-transformers/all-MiniLM-L6-v2} almacenados en bases FAISS, permitiendo búsqueda semántica eficiente. Las herramientas RAG implementadas retornan fragmentos relevantes con metadata completa, estableciendo una base sólida para un agente conversacional que consulta primero los apuntes y cita apropiadamente las fuentes.

Los resultados muestran que ambas segmentaciones son viables, con la segmentación A ofreciendo mayor control sobre la longitud y la segmentación B manteniendo mejor coherencia semántica. El sistema está listo para integración con un agente conversacional que orqueste las herramientas RAG y proporcione respuestas contextualizadas sobre el contenido del curso.

\section{Bibliograf\'ia}

\renewcommand{\refname}{}
\vspace{-1em}%
\begin{thebibliography}{00}

\bibitem{Reimers2019}
N. Reimers and I. Gurevych, ``Sentence-BERT: Sentence embeddings using siamese BERT-networks,'' in \emph{Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)}, 2019, pp. 3982--3992.

\bibitem{Johnson2019}
J. Johnson, M. Douze, and H. Jégou, ``Billion-scale similarity search with GPUs,'' \emph{IEEE Transactions on Big Data}, vol. 7, no. 3, pp. 535--547, 2019.

\bibitem{LangChain2024}
LangChain, ``LangChain Documentation,'' 2024. [Online]. Available: https://python.langchain.com/

\bibitem{Lewis2020}
P. Lewis et al., ``Retrieval-augmented generation for knowledge-intensive NLP tasks,'' in \emph{Advances in Neural Information Processing Systems}, vol. 33, 2020, pp. 9459--9474.

\bibitem{HuggingFace2024}
Hugging Face, ``Sentence Transformers,'' 2024. [Online]. Available: https://www.sbert.net/

\bibitem{FAISS2024}
Facebook AI Research, ``FAISS: A library for efficient similarity search and clustering of dense vectors,'' 2024. [Online]. Available: https://github.com/facebookresearch/faiss

\end{thebibliography}

\end{document}
